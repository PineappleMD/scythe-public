# scythe-public
This is a web scraper designed to handle pagination, with built-in evasion techniques to circumvent detection and automated logging mechanisms.
PLEASE NOTE: This web scraper was designed to pull data from specific sites, it is NOT a one program scrapes all solution. Retry and retry delay is not fully implemented.
Roadmap: Planning to add auto-rotating proxies with random user agents & smart reference pages which adapt to the previous page scraped.
